import streamlit as st
import cv2
from ultralytics import YOLO
import tempfile
import os
import numpy as np
import math
from PIL import Image
import time
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase, RTCConfiguration, WebRtcMode
import av
import threading
import queue
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Page configuration
st.set_page_config(
    page_title="Deteksi dan Klasifikasi Pose",
    page_icon="ğŸ¤¸â€â™‚ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS - Enhanced responsive design
st.markdown("""
<style>
    .main-header {
        text-align: center;
        background: linear-gradient(90deg, #FF6B6B, #4ECDC4);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        font-size: clamp(2rem, 5vw, 3rem);
        font-weight: bold;
        margin-bottom: 0.5rem;
    }
    .sub-header {
        text-align: center;
        color: #666;
        font-size: clamp(1rem, 3vw, 1.2rem);
        margin-bottom: 2rem;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1rem;
        border-radius: 15px;
        margin: 0.5rem 0;
        text-align: center;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
    }
    .info-box {
        background: linear-gradient(135deg, #74b9ff 0%, #0984e3 100%);
        color: white;
        padding: 1rem;
        border-radius: 15px;
        margin: 1rem 0;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
    }
    .success-box {
        background: linear-gradient(135deg, #00b894 0%, #00a085 100%);
        color: white;
        padding: 1rem;
        border-radius: 15px;
        margin: 1rem 0;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
    }
    .warning-box {
        background: linear-gradient(135deg, #fdcb6e 0%, #e17055 100%);
        color: white;
        padding: 1rem;
        border-radius: 15px;
        margin: 1rem 0;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
    }
    .error-box {
        background: linear-gradient(135deg, #fd79a8 0%, #e84393 100%);
        color: white;
        padding: 1rem;
        border-radius: 15px;
        margin: 1rem 0;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
    }
    
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 25px;
        padding: 0.5rem 2rem;
        font-weight: bold;
        transition: all 0.3s ease;
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 25px rgba(0,0,0,0.2);
    }
    
    /* Video container */
    .video-container {
        border: 3px solid #667eea;
        border-radius: 15px;
        overflow: hidden;
        box-shadow: 0 8px 25px rgba(0,0,0,0.1);
    }
    
    /* Mobile responsive */
    @media (max-width: 768px) {
        .stColumn {
            padding: 0 0.25rem;
        }
        .metric-card {
            padding: 0.75rem;
            font-size: 0.9rem;
        }
    }
</style>
""", unsafe_allow_html=True)

# Constants
CLASS_LABELS = {
    0: "Postur Buruk",
    1: "Postur Baik"
}

COLORS = {
    0: (0, 0, 255),    # Red for bad posture
    1: (0, 255, 0),    # Green for good posture
}

KEYPOINT_CONNECTIONS = [(0, 1), (1, 2)]

# Header
st.markdown('<h1 class="main-header">ğŸ¤¸â€â™‚ï¸ Pose Estimation AI</h1>', unsafe_allow_html=True)
st.markdown('<p class="sub-header">Analisis postur tubuh real-time dengan YOLO v8 Neural Network</p>', unsafe_allow_html=True)

# Enhanced WebRTC Configuration
RTC_CONFIGURATION = RTCConfiguration({
    "iceServers": [
        {"urls": ["stun:stun.l.google.com:19302"]},
        {"urls": ["stun:stun1.l.google.com:19302"]},
        {"urls": ["stun:stun2.l.google.com:19302"]},
        {"urls": ["stun:stun.services.mozilla.com:3478"]},
        {"urls": ["stun:stun.stunprotocol.org:3478"]},
    ],
    "iceTransportPolicy": "all",
    "bundlePolicy": "balanced",
    "rtcpMuxPolicy": "require",
    "iceCandidatePoolSize": 10
})

# Initialize session state
if 'stats' not in st.session_state:
    st.session_state.stats = {
        'total_frames': 0,
        'total_detections': 0,
        'good_posture': 0,
        'bad_posture': 0
    }

# Detect device type
def get_device_type():
    try:
        user_agent = st.context.headers.get("User-Agent", "").lower()
        if any(mobile in user_agent for mobile in ["mobile", "android", "iphone", "ipad"]):
            return "mobile"
        return "desktop"
    except:
        return "desktop"

device_type = get_device_type()

# Sidebar Configuration
with st.sidebar:
    st.markdown("### âš™ï¸ Konfigurasi")
    
    # Device info
    device_icon = "ğŸ“±" if device_type == "mobile" else "ğŸ’»"
    st.markdown(f"""
    <div class="info-box">
        {device_icon} <strong>Device:</strong> {device_type.title()}
    </div>
    """, unsafe_allow_html=True)
    
    # Model settings
    st.markdown("#### ğŸ¯ Pengaturan Deteksi")
    confidence_threshold = st.slider("Confidence Threshold", 0.1, 1.0, 0.5, 0.05)
    
    # Adaptive settings based on device
    if device_type == "mobile":
        image_size_options = [320, 480, 640]
        default_size_idx = 0
        video_width_options = [320, 480, 640]
        video_height_options = [240, 360, 480]
        fps_options = [10, 15, 20, 24]
        default_fps_idx = 2
    else:
        image_size_options = [320, 640, 1280]
        default_size_idx = 1
        video_width_options = [480, 640, 800, 1280]
        video_height_options = [360, 480, 600, 720]
        fps_options = [15, 20, 24, 30]
        default_fps_idx = 3
    
    image_size = st.selectbox("Ukuran Model", image_size_options, index=default_size_idx)
    
    # WebRTC settings
    st.markdown("#### ğŸ“¹ Pengaturan Video")
    video_width = st.selectbox("Lebar Video", video_width_options, index=1)
    video_height = st.selectbox("Tinggi Video", video_height_options, index=1)
    frame_rate = st.selectbox("Frame Rate", fps_options, index=default_fps_idx)
    
    # Display settings
    st.markdown("#### ğŸ¨ Opsi Tampilan")
    show_keypoints = st.checkbox("Tampilkan Keypoints", value=True)
    show_connections = st.checkbox("Tampilkan Koneksi", value=True)
    show_angles = st.checkbox("Tampilkan Sudut", value=True)
    show_confidence = st.checkbox("Tampilkan Confidence", value=True)
    show_fps = st.checkbox("Tampilkan FPS", value=True)
    
    # Advanced settings
    with st.expander("ğŸ”§ Pengaturan Lanjutan"):
        keypoint_threshold = st.slider("Keypoint Threshold", 0.1, 1.0, 0.5, 0.05)
        line_thickness = st.slider("Ketebalan Garis", 1, 8, 3)
        text_scale = st.slider("Skala Teks", 0.3, 1.5, 0.7, 0.1)
        processing_interval = st.slider("Interval Processing (ms)", 33, 200, 50, 17)
        
        # Performance settings
        st.markdown("**Optimasi Performa:**")
        use_gpu = st.checkbox("Gunakan GPU (jika tersedia)", value=True)
        async_processing = st.checkbox("Async Processing", value=True)

# Model loading with enhanced error handling
@st.cache_resource
def load_model():
    model_paths = [
        "pose2/train2/weights/best.pt",
        "best.pt",
        "models/best.pt",
        "weights/best.pt",
        "yolo_pose.pt"
    ]
    
    for model_path in model_paths:
        if os.path.exists(model_path):
            try:
                with st.spinner(f"ğŸ”„ Memuat model dari {model_path}..."):
                    # Try to use GPU if available
                    device = 'cuda' if use_gpu and cv2.cuda.getCudaEnabledDeviceCount() > 0 else 'cpu'
                    model = YOLO(model_path)
                    model.to(device)
                    return model, model_path, device
            except Exception as e:
                logger.error(f"Error loading model from {model_path}: {str(e)}")
                continue
    
    # Try to download a pretrained model if none found
    try:
        with st.spinner("ğŸ“¥ Mengunduh model YOLO pose..."):
            model = YOLO('yolov8n-pose.pt')  # Download pretrained pose model
            return model, 'yolov8n-pose.pt (downloaded)', 'cpu'
    except Exception as e:
        logger.error(f"Failed to download model: {str(e)}")
    
    return None, None, None

# Load model
model, model_path, device = load_model()

if model is None:
    st.markdown("""
    <div class="error-box">
        <h3>âŒ Model tidak ditemukan!</h3>
        <p>Pastikan salah satu file berikut ada:</p>
        <ul>
            <li>pose2/train2/weights/best.pt</li>
            <li>best.pt</li>
            <li>models/best.pt</li>
            <li>weights/best.pt</li>
        </ul>
        <p><strong>Atau:</strong> Aplikasi akan mencoba mengunduh model YOLO pose otomatis.</p>
    </div>
    """, unsafe_allow_html=True)
    st.stop()

st.sidebar.markdown(f"""
<div class="success-box">
    âœ… <strong>Model Ready!</strong><br>
    ğŸ“ Path: {model_path}<br>
    ğŸ’» Device: {device.upper()}<br>
    ğŸ”§ Size: {image_size}px
</div>
""", unsafe_allow_html=True)

def calculate_angle(a, b, c):
    """Calculate angle between three points"""
    if None in (a, b, c):
        return None
    
    try:
        ba = np.array(a) - np.array(b)
        bc = np.array(c) - np.array(b)
        
        dot_product = np.dot(ba, bc)
        norms = np.linalg.norm(ba) * np.linalg.norm(bc)
        
        if norms == 0:
            return None
            
        cosine_angle = dot_product / norms
        cosine_angle = np.clip(cosine_angle, -1.0, 1.0)
        angle = np.arccos(cosine_angle)
        return np.degrees(angle)
    except Exception as e:
        logger.warning(f"Error calculating angle: {e}")
        return None

def draw_pose_with_label(frame, keypoints_obj, label, box, conf_score):
    """Enhanced pose drawing with better visualization"""
    try:
        color = COLORS.get(label, (255, 255, 255))
        label_text = CLASS_LABELS.get(label, "Unknown")

        # Extract keypoints
        keypoints = keypoints_obj.xy[0].cpu().numpy()
        confs = keypoints_obj.conf[0].cpu().numpy()

        # Draw keypoints with enhanced visualization
        pts = []
        for i, (x, y) in enumerate(keypoints):
            if i < len(confs) and confs[i] > keypoint_threshold:
                pt = (int(x), int(y))
                pts.append(pt)
                
                if show_keypoints:
                    # Draw keypoint with outline
                    cv2.circle(frame, pt, 8, (0, 0, 0), -1)  # Black outline
                    cv2.circle(frame, pt, 6, color, -1)      # Colored center
                    cv2.circle(frame, pt, 8, (255, 255, 255), 2)  # White border
            else:
                pts.append(None)

        # Draw connections with gradient effect
        if show_connections:
            for i, j in KEYPOINT_CONNECTIONS:
                if i < len(pts) and j < len(pts) and pts[i] and pts[j]:
                    cv2.line(frame, pts[i], pts[j], color, line_thickness + 2, cv2.LINE_AA)
                    cv2.line(frame, pts[i], pts[j], (255, 255, 255), line_thickness, cv2.LINE_AA)

        # Calculate and display angle with better styling
        if show_angles and len(pts) >= 3 and all(pts[k] for k in [0, 1, 2]):
            angle = calculate_angle(pts[0], pts[1], pts[2])
            if angle is not None:
                pos = pts[1]
                angle_text = f"{int(angle)}Â°"
                
                # Background for angle text
                (text_width, text_height), baseline = cv2.getTextSize(
                    angle_text, cv2.FONT_HERSHEY_SIMPLEX, text_scale, 2
                )
                
                # Draw background rectangle
                bg_x1 = pos[0] + 10
                bg_y1 = pos[1] - text_height - 10
                bg_x2 = pos[0] + text_width + 20
                bg_y2 = pos[1] + 5
                
                cv2.rectangle(frame, (bg_x1, bg_y1), (bg_x2, bg_y2), (0, 0, 0), -1)
                cv2.rectangle(frame, (bg_x1, bg_y1), (bg_x2, bg_y2), (255, 255, 255), 2)
                
                # Draw angle text
                cv2.putText(
                    frame, angle_text, 
                    (pos[0] + 15, pos[1] - 5),
                    cv2.FONT_HERSHEY_SIMPLEX, text_scale, (0, 255, 255), 2, cv2.LINE_AA
                )

        # Draw enhanced bounding box and label
        if box is not None:
            x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())
            
            # Draw bounding box with rounded corners effect
            thickness = 3
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 0), thickness + 2)
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, thickness)
            
            # Enhanced label
            display_text = label_text
            if show_confidence:
                display_text += f" ({conf_score:.1%})"
            
            # Label background with gradient effect
            (text_width, text_height), _ = cv2.getTextSize(
                display_text, cv2.FONT_HERSHEY_DUPLEX, text_scale, 2
            )
            
            label_y1 = y1 - text_height - 20
            label_y2 = y1 - 5
            label_x2 = x1 + text_width + 20
            
            # Background
            cv2.rectangle(frame, (x1, label_y1), (label_x2, label_y2), (0, 0, 0), -1)
            cv2.rectangle(frame, (x1, label_y1), (label_x2, label_y2), color, -1)
            cv2.rectangle(frame, (x1, label_y1), (label_x2, label_y2), (255, 255, 255), 2)
            
            # Label text
            cv2.putText(
                frame, display_text, (x1 + 10, y1 - 10),
                cv2.FONT_HERSHEY_DUPLEX, text_scale, (255, 255, 255), 2, cv2.LINE_AA
            )

        return frame
    except Exception as e:
        logger.error(f"Error in draw_pose_with_label: {e}")
        return frame

def process_frame_detection(frame, fps_counter=None):
    """Optimized frame processing"""
    try:
        start_time = time.time()
        
        # Run YOLO inference
        results = model.predict(
            frame, 
            imgsz=image_size, 
            conf=confidence_threshold, 
            save=False, 
            verbose=False,
            device=device
        )

        detection_count = 0
        pose_results = []

        for result in results:
            boxes = result.boxes
            kpts = result.keypoints
            
            if boxes is not None and kpts is not None:
                for box, kp in zip(boxes, kpts):
                    try:
                        label = int(box.cls.cpu().item())
                        conf_score = float(box.conf.cpu().item())
                        
                        frame = draw_pose_with_label(frame, kp, label, box, conf_score)
                        
                        detection_count += 1
                        pose_results.append({
                            'label': CLASS_LABELS.get(label, 'Unknown'),
                            'confidence': conf_score,
                            'bbox': box.xyxy[0].cpu().numpy().tolist()
                        })
                    except Exception as e:
                        logger.warning(f"Error processing detection: {e}")
                        continue

        # Draw FPS if enabled
        if show_fps and fps_counter:
            processing_time = time.time() - start_time
            fps = 1.0 / processing_time if processing_time > 0 else 0
            fps_text = f"FPS: {fps:.1f}"
            
            cv2.putText(
                frame, fps_text, (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA
            )

        return frame, detection_count, pose_results
    except Exception as e:
        logger.error(f"Error in process_frame_detection: {e}")
        return frame, 0, []

# Enhanced WebRTC Video Transformer
class PoseDetectionTransformer(VideoTransformerBase):
    def __init__(self):
        self.frame_count = 0
        self.detection_count = 0
        self.good_posture_count = 0
        self.bad_posture_count = 0
        self.fps_counter = time.time()
        self.lock = threading.Lock()
        self.last_process_time = 0
        
    def transform(self, frame):
        try:
            # Convert frame
            img = frame.to_ndarray(format="bgr24")
            
            # Throttle processing based on interval
            current_time = time.time()
            if (current_time - self.last_process_time) * 1000 < processing_interval:
                return img
            
            self.last_process_time = current_time
            
            # Process frame
            processed_img, detection_count, pose_results = process_frame_detection(img, self.fps_counter)
            
            # Update statistics thread-safely
            with self.lock:
                self.frame_count += 1
                self.detection_count = detection_count
                
                # Update session state
                st.session_state.stats['total_frames'] = self.frame_count
                st.session_state.stats['total_detections'] += detection_count
                
                # Count posture types
                for result in pose_results:
                    if result['label'] == 'Postur Baik':
                        self.good_posture_count += 1
                        st.session_state.stats['good_posture'] += 1
                    else:
                        self.bad_posture_count += 1
                        st.session_state.stats['bad_posture'] += 1
            
            return processed_img
        except Exception as e:
            logger.error(f"Error in transformer: {e}")
            return frame.to_ndarray(format="bgr24")

def process_image(image):
    """Process uploaded image"""
    try:
        if isinstance(image, Image.Image):
            image_array = np.array(image)
            if len(image_array.shape) == 3 and image_array.shape[2] == 3:
                frame = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)
            else:
                frame = image_array
        else:
            frame = image
        
        processed_frame, detection_count, pose_results = process_frame_detection(frame)
        processed_rgb = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB)
        
        return processed_rgb, detection_count, pose_results
    except Exception as e:
        st.error(f"âŒ Error processing image: {str(e)}")
        return np.array(image), 0, []

def process_video(video_path):
    """Process uploaded video with progress tracking"""
    cap = cv2.VideoCapture(video_path)
    
    if not cap.isOpened():
        st.error("âŒ Tidak dapat membuka file video")
        return
    
    try:
        # Get video properties
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        duration = total_frames / fps if fps > 0 else 0
        
        # Display video info
        cols = st.columns(4)
        with cols[0]:
            st.metric("ğŸ“Š FPS", fps)
        with cols[1]:
            st.metric("ğŸï¸ Total Frame", total_frames)
        with cols[2]:
            st.metric("â±ï¸ Durasi", f"{duration:.1f}s")
        with cols[3]:
            st.metric("ğŸ“ Resolusi", f"{width}x{height}")
        
        # Create placeholders
        video_placeholder = st.empty()
        progress_bar = st.progress(0)
        status_text = st.empty()
        stats_placeholder = st.empty()
        
        # Statistics
        frame_count = 0
        total_detections = 0
        good_posture_count = 0
        bad_posture_count = 0
        
        # Process video frames
        start_time = time.time()
        
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            processed_frame, detection_count, pose_results = process_frame_detection(frame)
            
            # Update statistics
            total_detections += detection_count
            for result in pose_results:
                if result['label'] == 'Postur Baik':
                    good_posture_count += 1
                else:
                    bad_posture_count += 1
            
            # Display processed frame (every nth frame for performance)
            skip_frames = max(1, fps // 10)  # Show ~10 FPS
            if frame_count % skip_frames == 0:
                frame_rgb = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB)
                video_placeholder.image(frame_rgb, channels="RGB", use_container_width=True)
            
            # Update progress and stats
            frame_count += 1
            progress = frame_count / total_frames if total_frames > 0 else 0
            progress_bar.progress(progress)
            
            # Real-time stats
            elapsed_time = time.time() - start_time
            processing_fps = frame_count / elapsed_time if elapsed_time > 0 else 0
            
            status_text.markdown(f"""
            **âš¡ Processing:** Frame {frame_count:,}/{total_frames:,} | 
            **ğŸ”¥ Speed:** {processing_fps:.1f} FPS | 
            **â° ETA:** {((total_frames - frame_count) / processing_fps / 60):.1f}m
            """)
            
            # Update stats every 30 frames
            if frame_count % 30 == 0:
                cols = st.columns(4)
                with cols[0]:
                    st.metric("ğŸ¯ Deteksi", total_detections)
                with cols[1]:
                    st.metric("âœ… Postur Baik", good_posture_count)
                with cols[2]:
                    st.metric("âŒ Postur Buruk", bad_posture_count)
                with cols[3]:
                    accuracy = (good_posture_count / (good_posture_count + bad_posture_count)) * 100 if (good_posture_count + bad_posture_count) > 0 else 0
                    st.metric("ğŸ“ˆ Akurasi", f"{accuracy:.1f}%")
        
        cap.release()
        
        # Final results
        st.markdown("""
        <div class="success-box">
            <h3>ğŸ‰ Pemrosesan Video Selesai!</h3>
        </div>
        """, unsafe_allow_html=True)
        
        # Final statistics
        cols = st.columns(4)
        with cols[0]:
            st.metric("ğŸ¯ Total Deteksi", total_detections)
        with cols[1]:
            st.metric("âœ… Postur Baik", good_posture_count)
        with cols[2]:
            st.metric("âŒ Postur Buruk", bad_posture_count)
        with cols[3]:
            final_accuracy = (good_posture_count / (good_posture_count + bad_posture_count)) * 100 if (good_posture_count + bad_posture_count) > 0 else 0
            st.metric("ğŸ“ˆ Tingkat Postur Baik", f"{final_accuracy:.1f}%")
            
    except Exception as e:
        st.error(f"âŒ Error processing video: {str(e)}")
        logger.error(f"Video processing error: {e}")
    finally:
        cap.release()

# Main Interface
st.markdown("---")

# Create tabs with enhanced design
tab1, tab2, tab3 = st.tabs(["ğŸ“· Upload Gambar", "ğŸ“¹ Webcam Real-time", "ğŸ¬ Upload Video"])

# Tab 1: Image Upload
with tab1:
    st.markdown("### ğŸ“· Upload Gambar untuk Deteksi Pose")
    
    uploaded_image = st.file_uploader(
        "Pilih file gambar (JPG, PNG, BMP, TIFF)",
        type=['jpg', 'jpeg', 'png', 'bmp', 'tiff'],
        help="Upload gambar yang berisi orang untuk deteksi dan klasifikasi pose"
    )
    
    if uploaded_image is not None:
        try:
            image = Image.open(uploaded_image)
            
            # Responsive layout
            if device_type == "mobile":
                # Mobile layout - vertical stack
                st.markdown("#### ğŸ–¼ï¸ Gambar Asli")
                st.image(image, use_container_width=True)
                
                # Image info
                st.markdown(f"""
                <div class="info-box">
                    <h4>ğŸ“Š Informasi Gambar</h4>
                    <p><strong>Ukuran:</strong> {image.size[0]} x {image.size[1]} piksel</p>
                    <p><strong>Mode:</strong> {image.mode}</p>
                    <p><strong>Format:</strong> {image.format}</p>
                    <p><strong>Size:</strong> {uploaded_image.size / 1024:.1f} KB</p>
                </div>
                """, unsafe_allow_html=True)
                
                if st.button("ğŸ” Analisis Pose", type="primary", use_container_width=True):
                    with st.spinner("ğŸ¤– AI sedang menganalisis pose..."):
                        processed_image, detection_count, pose_results = process_image(image)
                    
                    st.markdown("#### ğŸ¯ Hasil Pemrosesan")
                    st.image(processed_image, use_container_width=True)
                    
                    # Results
                    if detection_count > 0:
                        st.markdown(f"""
                        <div class="success-box">
                            <h4>ğŸ‰ Analisis Berhasil!</h4>
                            <p><strong>Pose terdeteksi:</strong> {detection_count}</p>
                            <p><strong>Status:</strong> Pemrosesan selesai</p>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # Detailed results
                        with st.expander("ğŸ“‹ Detail Hasil Analisis"):
                            for i, result in enumerate(pose_results, 1):
                                posture_icon = "âœ…" if result['label'] == 'Postur Baik' else "âŒ"
                                st.markdown(f"""
                                **{posture_icon} Orang {i}:**
                                - **Klasifikasi:** {result['label']}
                                - **Confidence:** {result['confidence']:.2%}
                                - **Koordinat:** {[int(x) for x in result['bbox']]}
                                """)
                                st.markdown("---")
                    else:
                        st.markdown("""
                        <div class="warning-box">
                            <h4>âš ï¸ Tidak Ada Pose Terdeteksi</h4>
                            <p>Coba sesuaikan confidence threshold di sidebar atau gunakan gambar dengan pose yang lebih jelas.</p>
                        </div>
                        """, unsafe_allow_html=True)
            else:
                # Desktop layout - side by side
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("#### ğŸ–¼ï¸ Gambar Asli")
                    st.image(image, use_container_width=True)
                    
                    # Image info
                    st.markdown(f"""
                    <div class="info-box">
                        <h4>ğŸ“Š Informasi Gambar</h4>
                        <p><strong>Ukuran:</strong> {image.size[0]} x {image.size[1]} piksel</p>
                        <p><strong>Mode:</strong> {image.mode}</p>
                        <p><strong>Format:</strong> {image.format}</p>
                        <p><strong>Size:</strong> {uploaded_image.size / 1024:.1f} KB</p>
                    </div>
                    """, unsafe_allow_html=True)
                
                with col2:
                    if st.button("ğŸ” Analisis Pose", type="primary", use_container_width=True):
                        with st.spinner("ğŸ¤– AI sedang menganalisis pose..."):
                            processed_image, detection_count, pose_results = process_image(image)
                        
                        st.markdown("#### ğŸ¯ Hasil Pemrosesan")
                        st.image(processed_image, use_container_width=True)
                        
                        # Results
                        if detection_count > 0:
                            st.markdown(f"""
                            <div class="success-box">
                                <h4>ğŸ‰ Analisis Berhasil!</h4>
                                <p><strong>Pose terdeteksi:</strong> {detection_count}</p>
                                <p><strong>Status:</strong> Pemrosesan selesai</p>
                            </div>
                            """, unsafe_allow_html=True)
                            
                            # Detailed results
                            with st.expander("ğŸ“‹ Detail Hasil Analisis"):
                                for i, result in enumerate(pose_results, 1):
                                    posture_icon = "âœ…" if result['label'] == 'Postur Baik' else "âŒ"
                                    st.markdown(f"""
                                    **{posture_icon} Orang {i}:**
                                    - **Klasifikasi:** {result['label']}
                                    - **Confidence:** {result['confidence']:.2%}
                                    - **Koordinat:** {[int(x) for x in result['bbox']]}
                                    """)
                                    st.markdown("---")
                        else:
                            st.markdown("""
                            <div class="warning-box">
                                <h4>âš ï¸ Tidak Ada Pose Terdeteksi</h4>
                                <p>Coba sesuaikan confidence threshold di sidebar atau gunakan gambar dengan pose yang lebih jelas.</p>
                            </div>
                            """, unsafe_allow_html=True)
        
        except Exception as e:
            st.markdown(f"""
            <div class="error-box">
                <h4>âŒ Error Memproses Gambar</h4>
                <p>{str(e)}</p>
            </div>
            """, unsafe_allow_html=True)

# Tab 2: Real-time Webcam with Enhanced WebRTC
with tab2:
    st.markdown("### ğŸ“¹ Deteksi Pose Webcam Real-time")
    
    # Enhanced instructions based on device
    if device_type == "mobile":
        st.markdown("""
        <div class="info-box">
            <h4>ğŸ“± Petunjuk Webcam Mobile</h4>
            <p><strong>1.</strong> Pastikan browser memiliki izin akses kamera</p>
            <p><strong>2.</strong> Gunakan mode landscape untuk area deteksi lebih luas</p>
            <p><strong>3.</strong> Klik tombol <strong>START</strong> untuk memulai</p>
            <p><strong>4.</strong> Posisikan diri dalam frame dengan pencahayaan baik</p>
            <p><strong>5.</strong> AI akan menganalisis postur secara real-time</p>
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown("""
        <div class="info-box">
            <h4>ğŸ’» Petunjuk Webcam Desktop</h4>
            <p><strong>1.</strong> Klik tombol <strong>START</strong> untuk memulai streaming</p>
            <p><strong>2.</strong> Izinkan akses kamera ketika diminta browser</p>
            <p><strong>3.</strong> Posisikan diri di depan kamera (jarak 1-2 meter)</p>
            <p><strong>4.</strong> Pastikan pencahayaan yang cukup</p>
            <p><strong>5.</strong> AI akan menganalisis postur secara real-time</p>
        </div>
        """, unsafe_allow_html=True)
    
    # Reset stats button
    if st.button("ğŸ”„ Reset Statistik", help="Reset semua statistik sesi"):
        st.session_state.stats = {
            'total_frames': 0,
            'total_detections': 0,
            'good_posture': 0,
            'bad_posture': 0
        }
        st.success("âœ… Statistik direset!")
    
    # WebRTC Streamer with enhanced configuration
    try:
        # Determine camera facing mode
        facing_mode = "user" if device_type == "mobile" else {"exact": "environment"}
        
        webrtc_ctx = webrtc_streamer(
            key="pose-detection-enhanced",
            mode=WebRtcMode.SENDRECV,
            video_transformer_factory=PoseDetectionTransformer,
            rtc_configuration=RTC_CONFIGURATION,
            media_stream_constraints={
                "video": {
                    "width": {"ideal": video_width, "min": 320, "max": 1920},
                    "height": {"ideal": video_height, "min": 240, "max": 1080},
                    "frameRate": {"ideal": frame_rate, "min": 10, "max": 60},
                    "facingMode": facing_mode
                },
                "audio": False
            },
            async_processing=async_processing,
            video_html_attrs={
                "style": {"width": "100%", "margin": "0 auto", "border-radius": "15px"},
                "controls": False,
                "autoPlay": True,
            }
        )
        
        # Real-time statistics display
        if webrtc_ctx.video_transformer:
            st.markdown("### ğŸ“Š Statistik Real-time")
            
            # Create metrics layout
            if device_type == "mobile":
                # Mobile: 2x2 grid
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown(f"""
                    <div class="metric-card">
                        <h3>{webrtc_ctx.video_transformer.frame_count:,}</h3>
                        <p>ğŸï¸ Total Frame</p>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    st.markdown(f"""
                    <div class="metric-card">
                        <h3>{webrtc_ctx.video_transformer.good_posture_count:,}</h3>
                        <p>âœ… Postur Baik</p>
                    </div>
                    """, unsafe_allow_html=True)
                
                with col2:
                    st.markdown(f"""
                    <div class="metric-card">
                        <h3>{webrtc_ctx.video_transformer.detection_count}</h3>
                        <p>ğŸ¯ Deteksi Saat Ini</p>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    st.markdown(f"""
                    <div class="metric-card">
                        <h3>{webrtc_ctx.video_transformer.bad_posture_count:,}</h3>
                        <p>âŒ Postur Buruk</p>
                    </div>
                    """, unsafe_allow_html=True)
            else:
                # Desktop: 4 columns
                cols = st.columns(4)
                
                with cols[0]:
                    st.markdown(f"""
                    <div class="metric-card">
                        <h3>{webrtc_ctx.video_transformer.frame_count:,}</h3>
                        <p>ğŸï¸ Total Frame</p>
                    </div>
                    """, unsafe_allow_html=True)
                
                with cols[1]:
                    st.markdown(f"""
                    <div class="metric-card">
                        <h3>{webrtc_ctx.video_transformer.detection_count}</h3>
                        <p>ğŸ¯ Deteksi Saat Ini</p>
                    </div>
                    """, unsafe_allow_html=True)
                
                with cols[2]:
                    st.markdown(f"""
                    <div class="metric-card">
                        <h3>{webrtc_ctx.video_transformer.good_posture_count:,}</h3>
                        <p>âœ… Postur Baik</p>
                    </div>
                    """, unsafe_allow_html=True)
                
                with cols[3]:
                    st.markdown(f"""
                    <div class="metric-card">
                        <h3>{webrtc_ctx.video_transformer.bad_posture_count:,}</h3>
                        <p>âŒ Postur Buruk</p>
                    </div>
                    """, unsafe_allow_html=True)
            
            # Session summary
            total_postures = webrtc_ctx.video_transformer.good_posture_count + webrtc_ctx.video_transformer.bad_posture_count
            if total_postures > 0:
                good_percentage = (webrtc_ctx.video_transformer.good_posture_count / total_postures) * 100
                
                # Progress bar for posture quality
                st.markdown("#### ğŸ“ˆ Kualitas Postur Sesi")
                st.progress(good_percentage / 100)
                
                st.markdown(f"""
                <div class="success-box">
                    <h4>ğŸ“Š Ringkasan Sesi Real-time</h4>
                    <p><strong>ğŸ¯ Tingkat Postur Baik:</strong> {good_percentage:.1f}%</p>
                    <p><strong>ğŸï¸ Total Frame Diproses:</strong> {webrtc_ctx.video_transformer.frame_count:,}</p>
                    <p><strong>ğŸ‘¥ Total Deteksi Postur:</strong> {total_postures:,}</p>
                    <p><strong>âš¡ Status:</strong> {"ğŸŸ¢ Excellent" if good_percentage >= 80 else "ğŸŸ¡ Good" if good_percentage >= 60 else "ğŸ”´ Needs Improvement"}</p>
                </div>
                """, unsafe_allow_html=True)
            
            # Live recommendations
            if webrtc_ctx.video_transformer.detection_count > 0:
                st.markdown("#### ğŸ’¡ Saran Real-time")
                if webrtc_ctx.video_transformer.bad_posture_count > webrtc_ctx.video_transformer.good_posture_count:
                    st.markdown("""
                    <div class="warning-box">
                        <p><strong>âš ï¸ Perbaiki Postur:</strong></p>
                        <p>â€¢ Tegakkan punggung</p>
                        <p>â€¢ Sejajarkan bahu</p>
                        <p>â€¢ Angkat dagu sedikit</p>
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    st.markdown("""
                    <div class="success-box">
                        <p><strong>âœ… Postur Bagus!</strong></p>
                        <p>Pertahankan posisi ini</p>
                    </div>
                    """, unsafe_allow_html=True)
    
    except Exception as e:
        st.markdown(f"""
        <div class="error-box">
            <h4>âŒ Error Mengakses Webcam</h4>
            <p><strong>Error:</strong> {str(e)}</p>
            <h5>ğŸ”§ Troubleshooting:</h5>
            <p><strong>1.</strong> Pastikan browser mendukung WebRTC (Chrome/Firefox)</p>
            <p><strong>2.</strong> Periksa izin akses kamera di browser</p>
            <p><strong>3.</strong> Tutup aplikasi lain yang menggunakan kamera</p>
            <p><strong>4.</strong> Refresh halaman dan coba lagi</p>
            <p><strong>5.</strong> Coba gunakan browser lain</p>
        </div>
        """, unsafe_allow_html=True)

# Tab 3: Video Upload with Enhanced Processing
with tab3:
    st.markdown("### ğŸ¬ Upload Video untuk Deteksi Pose")
    
    uploaded_video = st.file_uploader(
        "Pilih file video (MP4, AVI, MOV, MKV, WMV)",
        type=['mp4', 'avi', 'mov', 'mkv', 'wmv'],
        help="Upload file video untuk analisis deteksi pose secara batch"
    )
    
    if uploaded_video is not None:
        # Enhanced video info
        file_size_mb = uploaded_video.size / (1024*1024)
        st.markdown(f"""
        <div class="info-box">
            <h4>ğŸ¬ Informasi Video</h4>
            <p><strong>ğŸ“ Nama:</strong> {uploaded_video.name}</p>
            <p><strong>ğŸ’¾ Ukuran:</strong> {file_size_mb:.2f} MB</p>
            <p><strong>ğŸ·ï¸ Tipe:</strong> {uploaded_video.type}</p>
            <p><strong>âš¡ Estimasi waktu:</strong> ~{file_size_mb * 2:.0f} detik</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Processing options
        col1, col2 = st.columns(2)
        with col1:
            skip_frames = st.selectbox(
                "Skip Frame (untuk mempercepat)", 
                [1, 2, 3, 5, 10], 
                index=1,
                help="Skip frame untuk mempercepat processing (1 = semua frame)"
            )
        with col2:
            show_preview = st.checkbox("Tampilkan Preview", value=True, help="Tampilkan video preview saat processing")
        
        if st.button("ğŸš€ Proses Video", type="primary", use_container_width=True):
            # Save uploaded file temporarily
            with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tfile:
                tfile.write(uploaded_video.read())
                temp_video_path = tfile.name
            
            try:
                with st.spinner("ğŸ¬ Memproses video..."):
                    process_video(temp_video_path)
            except Exception as e:
                st.markdown(f"""
                <div class="error-box">
                    <h4>âŒ Error Memproses Video</h4>
                    <p><strong>Error:</strong> {str(e)}</p>
                    <p>Coba dengan file video yang lebih kecil atau format yang berbeda.</p>
                </div>
                """, unsafe_allow_html=True)
            finally:
                # Clean up temporary file
                if os.path.exists(temp_video_path):
                    os.unlink(temp_video_path)

# Enhanced Tips Section
st.markdown("---")
st.markdown("### ğŸ’¡ Tips untuk Deteksi Pose yang Optimal")

if device_type == "mobile":
    # Mobile tips - stacked layout
    st.markdown("""
    <div class="info-box">
        <h4>ğŸ“± Tips Mobile Optimal</h4>
        <p><strong>ğŸ“¹ Kamera:</strong></p>
        <p>â€¢ Gunakan mode landscape untuk area deteksi lebih luas</p>
        <p>â€¢ Pastikan pencahayaan yang baik (hindari backlighting)</p>
        <p>â€¢ Jaga jarak 1.5-2 meter dari device</p>
        <p>â€¢ Gunakan tripod atau penyangga untuk stabilitas</p>
        
        <p><strong>ğŸ¯ Deteksi:</strong></p>
        <p>â€¢ Kenakan pakaian dengan warna kontras dari background</p>
        <p>â€¢ Hindari pakaian terlalu longgar</p>
        <p>â€¢ Posisikan seluruh tubuh dalam frame</p>
        <p>â€¢ Latar belakang yang simpel akan lebih baik</p>
        
        <p><strong>âš¡ Performa:</strong></p>
        <p>â€¢ Tutup aplikasi lain untuk menghemat RAM</p>
        <p>â€¢ Gunakan WiFi yang stabil</p>
        <p>â€¢ Kurangi resolusi jika lag</p>
        <p>â€¢ Aktifkan mode hemat baterai jika diperlukan</p>
    </div>
    """, unsafe_allow_html=True)
else:
    # Desktop tips - 3 column layout
    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("""
        <div class="info-box">
            <h4>ğŸ’» Setup Desktop</h4>
            <p><strong>ğŸ“¹ Kamera:</strong></p>
            <p>â€¢ Posisikan webcam setinggi mata</p>
            <p>â€¢ Jaga jarak 1-2 meter</p>
            <p>â€¢ Pencahayaan dari depan</p>
            <p>â€¢ Resolusi tinggi untuk akurasi</p>
            
            <p><strong>ğŸ’» Browser:</strong></p>
            <p>â€¢ Chrome/Firefox terbaru</p>
            <p>â€¢ Izinkan akses kamera</p>
            <p>â€¢ Tutup tab lain</p>
            <p>â€¢ Hardware acceleration ON</p>
        </div>
        """, unsafe_allow_html=True)

    with col2:
        st.markdown("""
        <div class="info-box">
            <h4>ğŸ¯ Optimasi Deteksi</h4>
            <p><strong>ğŸ‘¤ Postur:</strong></p>
            <p>â€¢ Duduk/berdiri tegak</p>
            <p>â€¢ Bahu sejajar</p>
            <p>â€¢ Kepala tegak</p>
            <p>â€¢ Seluruh tubuh dalam frame</p>
            
            <p><strong>ğŸ‘• Pakaian:</strong></p>
            <p>â€¢ Warna kontras dengan background</p>
            <p>â€¢ Hindari pakaian terlalu longgar</p>
            <p>â€¢ Tidak ada aksesoris menutupi</p>
            <p>â€¢ Pola sederhana lebih baik</p>
        </div>
        """, unsafe_allow_html=True)

    with col3:
        st.markdown("""
        <div class="info-box">
            <h4>âš™ï¸ Settings Optimal</h4>
            <p><strong>ğŸ”§ Model:</strong></p>
            <p>â€¢ Confidence: 0.5-0.7</p>
            <p>â€¢ Image size: 640px</p>
            <p>â€¢ Keypoint threshold: 0.5</p>
            <p>â€¢ GPU jika tersedia</p>
            
            <p><strong>ğŸ“¹ Video:</strong></p>
            <p>â€¢ 640x480 atau 800x600</p>
            <p>â€¢ 24-30 FPS</p>
            <p>â€¢ Stable internet</p>
            <p>â€¢ Processing interval: 50ms</p>
        </div>
        """, unsafe_allow_html=True)

# Advanced Troubleshooting
st.markdown("---")
st.markdown("### ğŸ”§ Troubleshooting Lanjutan")

with st.expander("ğŸš¨ Masalah Umum dan Solusi Lengkap"):
    st.markdown("""
    ### ğŸ“¹ **Masalah Webcam**
    
    **Problem: Webcam tidak muncul/blank**
    - âœ… Periksa izin browser: `chrome://settings/content/camera`
    - âœ… Restart browser setelah memberikan izin
    - âœ… Coba browser lain (Chrome/Firefox)
    - âœ… Update driver webcam (Windows: Device Manager)
    
    **Problem: Video lag/choppy**
    - âœ… Turunkan resolusi ke 480x360
    - âœ… Kurangi frame rate ke 15-20 FPS
    - âœ… Tingkatkan processing interval ke 100ms
    - âœ… Tutup aplikasi lain yang menggunakan kamera
    
    ### ğŸ¯ **Masalah Deteksi**
    
    **Problem: Tidak ada deteksi pose**
    - âœ… Turunkan confidence threshold ke 0.3
    - âœ… Pastikan seluruh tubuh dalam frame
    - âœ… Periksa pencahayaan (tidak terlalu gelap/terang)
    - âœ… Coba posisi yang lebih jelas
    
    **Problem: Deteksi tidak akurat**
    - âœ… Gunakan background yang kontras
    - âœ… Hindari pakaian dengan pola kompleks
    - âœ… Pastikan tidak ada objek menghalangi
    - âœ… Tingkatkan keypoint threshold ke 0.6
    
    ### âš¡ **Masalah Performa**
    
    **Problem: FPS rendah**
    - âœ… Gunakan model size 320px
    - âœ… Nonaktifkan opsi visual yang tidak perlu
    - âœ… Aktifkan GPU jika tersedia
    - âœ… Tutup tab browser lain
    
    **Problem: Browser crash/freeze**
    - âœ… Refresh halaman
    - âœ… Clear browser cache
    - âœ… Restart browser
    - âœ… Coba incognito mode
    
    ### ğŸ“± **Masalah Mobile**
    
    **Problem: Tidak bisa akses kamera mobile**
    - âœ… Pastikan menggunakan HTTPS
    - âœ… Gunakan Chrome Mobile atau Safari
    - âœ… Izinkan kamera di browser settings
    - âœ… Restart browser mobile
    
    **Problem: Performa lambat di mobile**
    - âœ… Gunakan resolusi 320x240
    - âœ… Frame rate maksimal 15 FPS
    - âœ… Tutup aplikasi lain
    - âœ… Gunakan WiFi yang stabil
    """)

# System Status
st.markdown("---")
st.markdown("### ğŸ“Š System Status")

col1, col2, col3, col4 = st.columns(4)

with col1:
    st.markdown(f"""
    <div class="metric-card">
        <h4>ğŸ¤– Model</h4>
        <p>âœ… Loaded</p>
        <small>{device.upper()}</small>
    </div>
    """, unsafe_allow_html=True)

with col2:
    st.markdown(f"""
    <div class="metric-card">
        <h4>ğŸ“± Device</h4>
        <p>{device_type.title()}</p>
        <small>Auto-detected</small>
    </div>
    """, unsafe_allow_html=True)

with col3:
    st.markdown(f"""
    <div class="metric-card">
        <h4>âš™ï¸ Config</h4>
        <p>{image_size}px</p>
        <small>Model size</small>
    </div>
    """, unsafe_allow_html=True)

with col4:
    total_sessions = st.session_state.stats['good_posture'] + st.session_state.stats['bad_posture']
    accuracy = (st.session_state.stats['good_posture'] / total_sessions * 100) if total_sessions > 0 else 0
    st.markdown(f"""
    <div class="metric-card">
        <h4>ğŸ“ˆ Session</h4>
        <p>{accuracy:.0f}%</p>
        <small>Accuracy</small>
    </div>
    """, unsafe_allow_html=True)

# Footer
st.markdown("---")
st.markdown("""
<div style="text-align: center; padding: 30px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; color: white; margin-top: 2rem;">
    <h3>ğŸ¤¸â€â™‚ï¸ Pose Estimation AI</h3>
    <p><strong>Powered by:</strong> YOLO v8 Neural Network â€¢ Streamlit â€¢ OpenCV</p>
    <p><strong>Compatible:</strong> ğŸ’» Desktop â€¢ ğŸ“± Mobile â€¢ ğŸ“Ÿ Tablet</p>
    <p><strong>Best Results:</strong> Good lighting â€¢ Clear posture â€¢ Stable connection</p>
    <br>
    <p><em>Developed with â¤ï¸ for better posture analysis</em></p>
</div>
""", unsafe_allow_html=True)
